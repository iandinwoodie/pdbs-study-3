---
title: "Binary Logistic Regression"
author: "Ian Dinwoodie"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
#library(plyr)
#library(broom)
#library(AER)
#library(boot)
opts_chunk$set(echo=TRUE)
set.seed(1)
```

# Loading the Data

Load the raw data and verify the expected dimensions.

```{r}
df <- readRDS('../data/tidy.Rds')
stopifnot(identical(dim(df)+0, c(1305, 275)))
str(df, list.len=5)
```

# Adjust the Data

TODO: Relocate this section to the tidy notebook.

```{r}
# Create dummy variables for the levels 1-4 of "behav_mod_strategy_used".
# We ignore levels 5 and 6 because they are irrelevant to the question.
df$has_systematic_desen <- ifelse(df$behav_mod_strategy_used==1, 1, 0)
df$has_systematic_desen[is.na(df$has_systematic_desen)] <- 0
df$has_systematic_desen <- as.integer(df$has_systematic_desen)
df$has_counter_conditioning <- ifelse(df$behav_mod_strategy_used==2, 1, 0)
df$has_counter_conditioning[is.na(df$has_counter_conditioning)] <- 0
df$has_counter_conditioning <- as.integer(df$has_counter_conditioning)
df$has_sd_and_cc <- ifelse(df$behav_mod_strategy_used==3, 1, 0)
df$has_sd_and_cc[is.na(df$has_sd_and_cc)] <- 0
df$has_sd_and_cc <- as.integer(df$has_sd_and_cc)
df$has_leadership <- ifelse(df$behav_mod_strategy_used==4, 1, 0)
df$has_leadership[is.na(df$has_leadership)] <- 0
df$has_leadership <- as.integer(df$has_leadership)
df <- subset(df, select=-behav_mod_strategy_used)
stopifnot(identical(dim(df)+0, c(1305, 278)))

# Correct training method entries.
# We consider dogs trained with any form of punishment to be excluded from a
# reward-only training style. We consider compulsion a form of punishment.
df$has_punish_based_training <- ifelse(
    ((df$has_punish_based_training==1) | (df$has_combo_based_training==1) 
     | (df$has_compulsion_based_training==1)), 1, 0)
df$has_reward_based_training <- ifelse(df$has_punish_based_training==1, 0,
                                       df$has_reward_based_training)
df <- subset(df, select=-c(has_combo_based_training,
                           has_compulsion_based_training))
stopifnot(identical(dim(df)+0, c(1305, 276)))

# Drop clicker/whistle from equipment since it is present in the behavior
# techniques.
df <- subset(df, select=-has_clicker)
stopifnot(identical(dim(df)+0, c(1305, 275)))

# TODO: explain the lines below (68-71)
df$is_trainer_credentialed <- ifelse(df$is_trainer_credentialed == 1, 1, 0)
df[is.na(df$is_trainer_credentialed), 'is_trainer_credentialed'] <- 0
df$is_trainer_cpdt_credentialed <- ifelse(
    df$is_trainer_cpdt_credentialed == 1, 1, 0)
df[is.na(df$is_trainer_cpdt_credentialed), 'is_trainer_cpdt_credentialed'] <- 0

df$is_consultant_credentialed <- ifelse(
    df$is_consultant_credentialed == 1, 1, 0)
df[is.na(df$is_consultant_credentialed), 'is_consultant_credentialed'] <- 0
df$is_consultant_cbcc_ka <- ifelse(df$is_consultant_cbcc_ka == 1, 1, 0)
df$is_consultant_cdbc <- ifelse(df$is_consultant_cdbc == 1, 1, 0)
df$is_consultant_acaab <- ifelse(df$is_consultant_acaab == 1, 1, 0)
df$is_consultant_dacvb <- ifelse(df$is_consultant_dacvb == 1, 1, 0)

str(df)
```

Retain only the columns necessary for analysis.

```{r}
# Retain only the columns to be used for analysis.
# where is neutered
# age
# breed <- we can't include this here because too many models
#          maybe we use the AKC breeding groups
# aggression
# age_of_acquisition
# is_multi_dog_household

# age of onset is usually 0-2
# you're less likely to get separation anxiety later on
# however, there is a blip for geriatrics getting senior onset anxiety

# dogs usually develop serious thunderstorm phobia at 5-9 years

predictors <- c(
  '^is_male$',
  '^has_seen_veterinarian$',
  '^has_seen_trainer$',
  '^has_seen_consultant$',
  '^has_flat_collar$',
  '^has_martingale$',
  '^has_prong_collar$',
  '^has_head_halter$',
  '^has_harness_with_chest_lead$',
  '^has_harness_with_shoulder_lead$',
  '^has_non_remote_electric_collar$',
  '^has_remote_electric_collar$',
  '^has_muzzle$',
  '^has_other_training_equipment$',
  '^has_fluoxetine$',
  '^has_sertraline$',
  '^has_paroxetine$',
  '^has_citalopram$',
  '^has_escitalopram$',
  '^has_clomipramine$',
  '^has_trazodone$',
  '^has_buspirone$',
  '^has_valium$',
  '^has_clonidine$',
  '^has_acepromazine$',
  '^has_diphenhydramine$',
  '^has_other_medication$',
  '^has_acupuncture$',
  '^has_aromatherapy$',
  '^has_cannabidiol$',
  '^has_chiropracy$',
  '^has_dog_tv$',
  '^has_herbal_medicine$',
  '^has_homeopathy$',
  '^has_hormone_therapy$',
  '^has_hydrotherapy$',
  '^has_magnetic_field_therapy$',
  '^has_massage_therapy$',
  '^has_music_therapy$',
  '^has_nutraceuticals$',
  '^has_pheromone_therapy$',
  '^has_pressure_wraps$',
  '^has_reiki$',
  '^has_vision_blocking$',
  '^has_systematic_desen$',
  '^has_counter_conditioning$',
  '^has_sd_and_cc$',
  '^has_leadership$',
  '^has_mental_stimulation$',
  '^has_relaxation_protocol$',
  '^has_inc_physical_exercise$',
  '^has_habituation$',
  '^has_flooding$',
  '^has_response_blocking$',
  '^has_management$',
  '^has_red_of_stressors$',
  '^has_clicker_training$',
  '^has_play$',
  '^has_dog_sports$',
  '^has_ignoring_bad_behav$',
  '^has_training_alternatives$',
  '^has_short_freq_sessions$',
  '^has_group_classes$',
  '^has_private_sessions$',
  '^has_change_in_diet$',
  '^has_improved_comm$',
  '^has_other_behav_mod_technique$',
  '^has_exhibited_aggression$',
  '^has_reward_based_training$',
  '^is_trainer_credentialed$',
  '^is_trainer_cpdt_credentialed$',
  '^is_consultant_credentialed$',
  '^is_consultant_cbcc_ka$',
  '^is_consultant_cdbc$',
  '^is_consultant_acaab$',
  '^is_consultant_dacvb$'
)

# break into 4 groups:
# - inanimate
# - animate
# - situational
# - generalized
outcomes <- c(
  # need overall column
  '^thunderstorm_phobia_rating$', # inanimate
  '^non_thunderstorm_noise_phobia_rating$', # inanimate
  '^crowd_phobia_rating$', # situational
  '^fear_of_other_dogs_rating$', # animate
  '^ptsd_rating$', # situational
  '^general_anxiety_rating$', # generalized
  '^situation_anxiety_rating$', # situational
  '^veterinary_anxiety_rating$', # situational
  '^separation_anxiety_rating$', # situational
  '^anxiety_in_the_car_rating$', # situational
  '^other_fear_anxiety_rating$' # see designations
)
pattern <- paste(c(predictors, outcomes), collapse='|')
idx <- grep(pattern, names(df))
df <- df[, idx]
dim(df)
```

All remaining columns except for the response to treatment for aggression scores
are factors. Update the column types to reflect this.

```{r}
for (col in names(df)) {
  if (col == 'thunderstorm_phobia_rating') next
  if (col == 'non_thunderstorm_noise_phobia_rating') next
  if (col == 'crowd_phobia_rating') next
  if (col == 'fear_of_other_dogs_rating') next
  if (col == 'ptsd_rating') next
  if (col == 'general_anxiety_rating') next
  if (col == 'situation_anxiety_rating') next
  if (col == 'veterinary_anxiety_rating') next
  if (col == 'separation_anxiety_rating') next
  if (col == 'anxiety_in_the_car_rating') next
  if (col == 'other_fear_anxiety_rating') next
  df[, col] <- as.factor(df[, col])
}

str(df)
```

Get the number of dogs that used equipment:

```{r}
# TODO: Move to EDA notebook.
#df$used_equip <- ifelse(
#  (df$behavior_tech_used_1 == 1 | df$behavior_tech_used_2 == 1
#   | df$behavior_tech_used_3 == 1 | df$behavior_tech_used_4 == 1
#   | df$behavior_tech_used_5 == 1 | df$behavior_tech_used_6 == 1
#   | df$behavior_tech_used_7 == 1 | df$behavior_tech_used_8 == 1
#   | df$behavior_tech_used_9 == 1 | df$behavior_tech_used_10 == 1
#   | df$behavior_tech_used_11 == 1 | df$behavior_tech_used_12 == 1
#   | df$behavior_tech_used_13 == 1 | df$behavior_tech_used_14 == 1
#   | df$behavior_tech_used_15 == 1 | df$behavior_tech_used_16 == 1
#   | df$behavior_tech_used_17 == 1 | df$behavior_tech_used_18 == 1
#   | df$behavior_tech_used_19 == 1), TRUE, FALSE)
#has_mental_stimulation
#has_relaxation_protocol
#has_inc_physical_exercise
#has_habituation
#has_flooding
#has_response_blocking
#has_management
#has_red_of_stressors
#has_clicker_training
#has_play
#has_dog_sports
#has_ignoring_bad_behav
#has_training_alternatives
#has_short_freq_sessions
#has_group_classes
#has_private_sessions
#has_change_in_diet
#has_improved_comm
#has_other_behav_mod_technique
#
#summary(df$used_equip)
```

General rule of thumb for logistic regression is that each variable should have
at least 10 responses per response option. We apply this rule of thumb below.

```{r}
# Drop the columns that do not meet the minimum response cutoff.
apply_binary_response_criteria <- function(df, min_cutoff=10)
{
  drops <- NULL
  outcomes <- NULL
  for (col in names(df)) {
    if (col == 'thunderstorm_phobia_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    if (col == 'non_thunderstorm_noise_phobia_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    if (col == 'crowd_phobia_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    if (col == 'fear_of_other_dogs_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    if (col == 'ptsd_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    if (col == 'general_anxiety_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    if (col == 'situation_anxiety_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    if (col == 'veterinary_anxiety_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    if (col == 'separation_anxiety_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    if (col == 'anxiety_in_the_car_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    if (col == 'other_fear_anxiety_rating') next
    {
        outcomes <- c(outcomes, col)
        next
    }
    counts <- count(df[, col])
    if (nrow(counts) < 2) {
      drops <- c(drops, col)
      next
    }
    
    for (row in 1:nrow(counts)) {
      if (counts[row, "freq"] < min_cutoff) {
        drops <- c(drops, col)
        break
      }
    }
  }
  
  return(df[, !(names(df) %in% drops)])
}

apply_min_xtab <- function(df, cutoff=10)
{
  drops <- NULL
  for (col in names(df)) {
    if (col == outcome) next
    xtab <- table(df[,col], df[,outcome])
    if (min(xtab) < cutoff) {
      drops <- c(drops, col)
      break
    }
  }
  
  print(drops)
  return(df[, !(names(df) %in% drops)])
}

df <- apply_binary_response_criteria(df)
summary(df)
```

Now we initialize other functions that will be reused throughout the analysis.

```{r}
get_agg_data_frame <- function(df, pred.patterns, outcome, excludes)
{
  pattern <- paste(c(pred.patterns, outcome), collapse='|')
  idx <- grep(pattern, names(df))
  df.out <- df[, idx]

  # Format the outcome as a factor with order.
  #df.out[,outcome] <- round(df.out[, outcome], 0)
  df.out[,outcome] <- factor(
      df.out[, outcome], levels=c("1","2","3","4","5","6","7"), ordered=TRUE)
  
  if (length(excludes) > 0) {
    # Exclude variables that cause issues for the model.
    df.out <- df.out[, !colnames(df.out) %in% excludes]
  }
  
  # Drop rows with null values for the outcome.
  df.out <- df.out[!is.na(df.out[, outcome]), ]
  
  return(df.out)
}
```

```{r}
# Drops NAs before regression
df <- df[!is.na(df$is_male),]
```

# Overall Aggression

```{r agg_avg_df}
# Generate the desired subset data frame and collapse Likert outcome to be
# dichotomous.
outcome <- "agg_avg"
excludes <- vector()
df_agg <- apply_binary_response_criteria(
    get_agg_data_frame(df, predictors, outcome, excludes))
df_agg$agg_avg <- as.factor(ifelse(df_agg$agg_avg <= 4, 0, 1))

summary(df_agg)
```

```{r agg_avg_glm, warning=FALSE}
# Fit model to data.
f <- as.formula(paste0(outcome, "~", "."))
m <- glm(f, data=df_agg, family="binomial")
summary(m)

print(vif(m))

df_results <- broom::tidy(m, conf.int=TRUE, exponentiate=TRUE)
#df_results$p.value <- p.adjust(df_results$p.value, method='BH')
df_results$sig <- ''
df_results[df_results$p.value <= .05, 'sig'] <- '*'
df_results[df_results$p.value <= .01, 'sig'] <- '**'
df_results[df_results$p.value <= .001, 'sig'] <- '***'
for (i in 1:nrow(df_results)) {
  if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
  if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
    df_results[i, 'sig'] <- ''
  }
}

knitr::kable(df_results)
```

# Conflict Aggression

```{r agg_conf_df}
# Generate the desired subset data frame and collapse Likert outcome to be
# dichotomous.
outcome <- 'thunderstorm_phobia_rating'
excludes <- vector()
df_agg <- apply_binary_response_criteria(
    get_agg_data_frame(df, predictors, outcome, excludes),
    min_cutoff=20)
df_agg$thunderstorm_phobia_rating <- as.factor(
  ifelse(df_agg$thunderstorm_phobia_rating <= 4, 0, 1))

summary(df_agg)
```

```{r agg_conf_glm, warning=FALSE}
# Fit model to data.
f <- as.formula(paste0(outcome, "~", "."))
m <- glm(f, data=df_agg, family="binomial")
summary(m)

print(vif(m))

df_results <- broom::tidy(m, conf.int=TRUE, exponentiate=TRUE)
#df_results$p.value <- p.adjust(df_results$p.value, method='BH')
df_results$sig <- ''
df_results[df_results$p.value <= .05, 'sig'] <- '*'
df_results[df_results$p.value <= .01, 'sig'] <- '**'
df_results[df_results$p.value <= .001, 'sig'] <- '***'
for (i in 1:nrow(df_results)) {
  if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
  if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
    df_results[i, 'sig'] <- ''
  }
}

knitr::kable(df_results)
```

# I.D.H. Aggression

```{r agg_idh_df}
# Generate the desired subset data frame and collapse Likert outcome to be
# dichotomous.
outcome <- "agg_idh"
excludes <- vector()
df_agg <- apply_binary_response_criteria(
    get_agg_data_frame(df, predictors, outcome, excludes),
    min_cutoff=10)
df_agg$agg_idh <- as.factor(ifelse(df_agg$agg_idh <= 4, 0, 1))

summary(df_agg)
```

```{r agg_idh_glm, warning=FALSE}
# Fit model to data.
f <- as.formula(paste0(outcome, "~", "."))
m <- glm(f, data=df_agg, family="binomial")
summary(m)

print(vif(m))

df_results <- broom::tidy(m, conf.int=TRUE, exponentiate=TRUE)
#df_results$p.value <- p.adjust(df_results$p.value, method='BH')
df_results$sig <- ''
df_results[df_results$p.value <= .05, 'sig'] <- '*'
df_results[df_results$p.value <= .01, 'sig'] <- '**'
df_results[df_results$p.value <= .001, 'sig'] <- '***'
for (i in 1:nrow(df_results)) {
  if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
  if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
    df_results[i, 'sig'] <- ''
  }
}

knitr::kable(df_results)
```

# External Aggression (People)

```{r agg_ext_ppl_df}
# Generate the desired subset data frame and collapse Likert outcome to be
# dichotomous.
outcome <- "agg_ext_ppl"
excludes <- vector()
df_agg <- apply_binary_response_criteria(
    get_agg_data_frame(df, predictors, outcome, excludes),
    min_cutoff=10)
df_agg$agg_ext_ppl <- as.factor(ifelse(df_agg$agg_ext_ppl <= 4, 0, 1))

summary(df_agg)
```

```{r agg_ext_ppl_glm, warning=FALSE}
# Fit model to data.
f <- as.formula(paste0(outcome, "~", "."))
m <- glm(f, data=df_agg, family="binomial")
summary(m)

print(vif(m))

df_results <- broom::tidy(m, conf.int=TRUE, exponentiate=TRUE)
#df_results$p.value <- p.adjust(df_results$p.value, method='BH')
df_results$sig <- ''
df_results[df_results$p.value <= .05, 'sig'] <- '*'
df_results[df_results$p.value <= .01, 'sig'] <- '**'
df_results[df_results$p.value <= .001, 'sig'] <- '***'
for (i in 1:nrow(df_results)) {
  if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
  if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
    df_results[i, 'sig'] <- ''
  }
}

knitr::kable(df_results)
```

# External Aggression (Dogs)

```{r agg_ext_dog_df}
# Generate the desired subset data frame and collapse Likert outcome to be
# dichotomous.
outcome <- "agg_ext_dog"
excludes <- vector()
df_agg <- apply_binary_response_criteria(
    get_agg_data_frame(df, predictors, outcome, excludes),
    min_cutoff=10)
df_agg$agg_ext_dog <- as.factor(ifelse(df_agg$agg_ext_dog <= 4, 0, 1))

summary(df_agg)
```

```{r agg_ext_dog_glm, warning=FALSE}
# Fit model to data.
f <- as.formula(paste0(outcome, "~", "."))
m <- glm(f, data=df_agg, family="binomial")
summary(m)

print(vif(m))

df_results <- broom::tidy(m, conf.int=TRUE, exponentiate=TRUE)
#df_results$p.value <- p.adjust(df_results$p.value, method='BH')
df_results$sig <- ''
df_results[df_results$p.value <= .05, 'sig'] <- '*'
df_results[df_results$p.value <= .01, 'sig'] <- '**'
df_results[df_results$p.value <= .001, 'sig'] <- '***'
for (i in 1:nrow(df_results)) {
  if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
  if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
    df_results[i, 'sig'] <- ''
  }
}

knitr::kable(df_results)
```

# Predatory Aggression

```{r agg_pred_df}
# Generate the desired subset data frame and collapse Likert outcome to be
# dichotomous.
outcome <- "agg_pred"
excludes <- vector()
df_agg <- apply_binary_response_criteria(
    get_agg_data_frame(df, predictors, outcome, excludes),
    min_cutoff=10)
df_agg$agg_pred <- as.factor(ifelse(df_agg$agg_pred <= 4, 0, 1))

# Collinearity adjustments.
df_agg <- subset(df_agg, select=-consultant_cred) # VIF 12.67

summary(df_agg)
```

```{r agg_pred_glm, warning=FALSE}
# Fit model to data.
f <- as.formula(paste0(outcome, "~", "."))
m <- glm(f, data=df_agg, family="binomial")
summary(m)

print(vif(m))

df_results <- broom::tidy(m, conf.int=TRUE, exponentiate=TRUE)
#df_results$p.value <- p.adjust(df_results$p.value, method='BH')
df_results$sig <- ''
df_results[df_results$p.value <= .05, 'sig'] <- '*'
df_results[df_results$p.value <= .01, 'sig'] <- '**'
df_results[df_results$p.value <= .001, 'sig'] <- '***'
for (i in 1:nrow(df_results)) {
  if (is.na(df_results[i, 'conf.low']) | is.na(df_results[i, 'conf.high'])) next
  if ((df_results[i, 'conf.low'] < 1) & (df_results[i, 'conf.high'] > 1)) {
    df_results[i, 'sig'] <- ''
  }
}

knitr::kable(df_results)
```
